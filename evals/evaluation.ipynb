{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810f4498",
   "metadata": {},
   "source": [
    "# Legal RAG Evaluation - Ground Truth Dataset Creation\n",
    "\n",
    "This notebook creates a ground truth Q&A dataset for evaluating the legal RAG pipeline.\n",
    "Focus: Data usage questions with large context chunks (2000+ tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import textwrap\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "sys.path.append('../backend')\n",
    "from legal_rag import LegalRAGBackend\n",
    "from langchain_openai import AzureOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149bd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_ENDPOINT = \"https://ironclad-openai-001.openai.azure.com/\"\n",
    "AZURE_OPENAI_API_KEY = \"936856630b764210913d9a8fd6c8212b\"\n",
    "AZURE_DEPLOYMENT_NAME = \"gpt-4o\"\n",
    "\n",
    "rag_backend = LegalRAGBackend()\n",
    "\n",
    "azure_client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_USAGE_QUERIES = [\n",
    "    \"Can we use client data to develop or test new services?\",\n",
    "    \"client data usage for development and testing\",\n",
    "    \"PHI data usage restrictions\",\n",
    "    \"artificial intelligence machine learning restrictions\",\n",
    "    \"data retention requirements timelines\",\n",
    "    \"client consent requirements data usage\",\n",
    "    \"third-party vendor data processing\",\n",
    "    \"human oversight AI decision making\",\n",
    "    \"IP ownership rights client data\",\n",
    "    \"cloud storage limitations PHI\",\n",
    "    \"data sharing restrictions\",\n",
    "    \"client data anonymization requirements\"\n",
    "]\n",
    "\n",
    "KEY_CLIENTS = [\"Aetna Life Insurance Company\", \"Aerotek\", \"1199 SEIU National Benefit Funds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ebc930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_large_context_chunks(queries: List[str], clients: List[str], top_k: int = 10) -> List[Dict[str, Any]]:\n",
    "    contexts = []\n",
    "    \n",
    "    for query in queries:\n",
    "        for client in clients:\n",
    "            try:\n",
    "                response = rag_backend.query_s3_vector_store(\n",
    "                    query_text=query,\n",
    "                    client_account_filter=client,\n",
    "                    top_k=top_k\n",
    "                )\n",
    "                \n",
    "                if response and 'vectors' in response:\n",
    "                    for vector in response['vectors']:\n",
    "                        metadata = vector.get('metadata', {})\n",
    "                        text = metadata.get('text', '')\n",
    "                        \n",
    "                        if len(text) >= 2000:\n",
    "                            contexts.append({\n",
    "                                'text': text,\n",
    "                                'client': client,\n",
    "                                'source': metadata.get('s3_path', 'unknown'),\n",
    "                                'document_type': metadata.get('document_type', 'unknown'),\n",
    "                                'query_used': query\n",
    "                            })\n",
    "                            \n",
    "                time.sleep(0.5)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error querying {query} for {client}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485000bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa_pair(context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    system_prompt = textwrap.dedent(\"\"\"\n",
    "        You are an expert creating multiple-choice questions from legal documents.\n",
    "        Create questions about data usage, privacy, AI/ML restrictions, and related legal topics.\n",
    "        \n",
    "        Output format (Python dictionary):\n",
    "        {\n",
    "            \"question\": \"Question text\",\n",
    "            \"options\": {\n",
    "                \"A\": \"Option A text\",\n",
    "                \"B\": \"Option B text\", \n",
    "                \"C\": \"Option C text\",\n",
    "                \"D\": \"Option D text\"\n",
    "            },\n",
    "            \"correct_answer\": \"A/B/C/D\",\n",
    "            \"explanation\": \"Brief explanation\"\n",
    "        }\n",
    "        \n",
    "        ONLY output the dictionary.\n",
    "        \"\"\")\n",
    "    \n",
    "    human_prompt = f\"\"\"\n",
    "        Create a multiple-choice question based on this legal document text:\n",
    "        \n",
    "        Client: {context['client']}\n",
    "        Document Type: {context['document_type']}\n",
    "        \n",
    "        Text:\n",
    "        {context['text'][:3000]}\n",
    "        \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = azure_client.chat.completions.create(\n",
    "            model=AZURE_DEPLOYMENT_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": human_prompt}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        qa_text = response.choices[0].message.content.strip()\n",
    "        qa_dict = eval(qa_text)\n",
    "        \n",
    "        qa_dict['source'] = context['source']\n",
    "        qa_dict['client'] = context['client']\n",
    "        qa_dict['document_type'] = context['document_type']\n",
    "        \n",
    "        return qa_dict\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Q&A: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe9be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_options(qa_list: List[Dict], seed: int = 42) -> List[Dict]:\n",
    "    random.seed(seed)\n",
    "    \n",
    "    for qa in qa_list:\n",
    "        options = list(qa[\"options\"].items())\n",
    "        random.shuffle(options)\n",
    "        \n",
    "        new_option_keys = ['A', 'B', 'C', 'D']\n",
    "        new_options = {new_key: value for new_key, (_, value) in zip(new_option_keys, options)}\n",
    "        \n",
    "        correct_answer_value = qa[\"options\"][qa[\"correct_answer\"]]\n",
    "        correct_answer_key = next(new_key for new_key, value in new_options.items() if value == correct_answer_value)\n",
    "        \n",
    "        qa[\"options\"] = new_options\n",
    "        qa[\"correct_answer\"] = correct_answer_key\n",
    "    \n",
    "    return qa_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d767f7",
   "metadata": {},
   "source": [
    "## Step 1: Collect Large Context Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5555dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Collecting large context chunks for data usage topics...\")\n",
    "contexts = get_large_context_chunks(DATA_USAGE_QUERIES, KEY_CLIENTS, top_k=5)\n",
    "\n",
    "print(f\"Collected {len(contexts)} context chunks\")\n",
    "print(f\"Average length: {sum(len(c['text']) for c in contexts) / len(contexts):.0f} characters\")\n",
    "\n",
    "for i, ctx in enumerate(contexts[:3]):\n",
    "    print(f\"\\nContext {i+1}:\")\n",
    "    print(f\"Client: {ctx['client']}\")\n",
    "    print(f\"Doc Type: {ctx['document_type']}\")\n",
    "    print(f\"Length: {len(ctx['text'])} chars\")\n",
    "    print(f\"Preview: {ctx['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81541094",
   "metadata": {},
   "source": [
    "## Step 2: Generate Q&A Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_QA_COUNT = 30\n",
    "qa_dataset = []\n",
    "\n",
    "random.seed(42)\n",
    "selected_contexts = random.sample(contexts, min(TARGET_QA_COUNT, len(contexts)))\n",
    "\n",
    "print(f\"Generating {TARGET_QA_COUNT} Q&A pairs...\")\n",
    "\n",
    "for i, context in enumerate(tqdm(selected_contexts, desc=\"Generating Q&A\")):\n",
    "    qa_pair = generate_qa_pair(context)\n",
    "    \n",
    "    if qa_pair:\n",
    "        qa_dataset.append(qa_pair)\n",
    "        print(f\"\\nQ&A {len(qa_dataset)}:\")\n",
    "        print(f\"Q: {qa_pair['question']}\")\n",
    "        print(f\"A: {qa_pair['correct_answer']} - {qa_pair['options'][qa_pair['correct_answer']]}\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    if len(qa_dataset) >= TARGET_QA_COUNT:\n",
    "        break\n",
    "\n",
    "print(f\"\\nGenerated {len(qa_dataset)} Q&A pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d55a313",
   "metadata": {},
   "source": [
    "## Step 3: Process and Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2967b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset_shuffled = shuffle_options(qa_dataset, seed=42)\n",
    "\n",
    "with open(\"qa_list.json\", \"w\") as f:\n",
    "    json.dump(qa_dataset_shuffled, f, indent=4)\n",
    "\n",
    "print(f\"Saved {len(qa_dataset_shuffled)} Q&A pairs to qa_list.json\")\n",
    "\n",
    "print(\"\\nDataset summary:\")\n",
    "clients = [qa['client'] for qa in qa_dataset_shuffled]\n",
    "doc_types = [qa['document_type'] for qa in qa_dataset_shuffled]\n",
    "\n",
    "from collections import Counter\n",
    "print(f\"Clients: {dict(Counter(clients))}\")\n",
    "print(f\"Document types: {dict(Counter(doc_types))}\")\n",
    "\n",
    "print(\"\\nSample Q&A:\")\n",
    "for i, qa in enumerate(qa_dataset_shuffled[:2]):\n",
    "    print(f\"\\n{i+1}. {qa['question']}\")\n",
    "    for opt, text in qa['options'].items():\n",
    "        marker = \"âœ“\" if opt == qa['correct_answer'] else \" \"\n",
    "        print(f\"  {marker} {opt}: {text}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
